{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fab43d4b-b6a8-41c5-b2d2-271e88c90cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from doctr.models import ocr_predictor\n",
    "from doctr.io import DocumentFile\n",
    "from datetime import datetime\n",
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "# on windows machine potentially necessary\n",
    "#import os\n",
    "# insert the GTK3 Runtime folder at the beginning. Can be bin or lib, depending on path you choose while installing.\n",
    "#GTK_FOLDER = r'C:\\Program Files\\GTK3-Runtime Win64\\bin'\n",
    "#os.environ['PATH'] = GTK_FOLDER + os.pathsep + os.environ.get('PATH', '')\n",
    "\n",
    "data_dir = 'data'\n",
    "annotations_dir = f'{data_dir}/annotations'\n",
    "# Ensure the 'annotations' directory exists\n",
    "if not os.path.exists(annotations_dir):\n",
    "    os.makedirs(annotations_dir)\n",
    "orig_images_path = f'{data_dir}/orig_images'\n",
    "image_paths = os.listdir(orig_images_path)\n",
    "image_paths = [os.path.join(orig_images_path,i) for i in image_paths]\n",
    "labels_file = os.path.join(annotations_dir, 'labels.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "243198a3-53bd-4814-8321-09f2df08239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize a dictionary to hold the JSON structure for labels\n",
    "# labels = {}\n",
    "\n",
    "# # Load model(s)\n",
    "# model = ocr_predictor(det_arch='db_resnet50', reco_arch='parseq', pretrained=True)\n",
    "\n",
    "# for image_path in image_paths: \n",
    "#     name_of_label = image_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "#     img = Image.open(image_path)\n",
    "#     # Check if the image is in landscape (width > height)\n",
    "#     if img.width > img.height:\n",
    "#         # Rotate the image by 270 degrees clockwise\n",
    "#         img = img.transpose(Image.Transpose.ROTATE_270)\n",
    "#     doc = DocumentFile.from_images(image_path)\n",
    "#     # Analyze\n",
    "#     result = model(doc)\n",
    "#     data = result.export()\n",
    "#     data = data[\"pages\"][0]\n",
    "\n",
    "#     # Loop through each block, line, and word to extract the words and create labels\n",
    "#     for block in data['blocks']:\n",
    "#         for line in block['lines']:\n",
    "#             for word in line['words']:\n",
    "#                 # Get the word coordinates\n",
    "#                 coords = word['geometry']\n",
    "#                 # Calculate the coordinates on the image\n",
    "#                 left = img.width * coords[0][0]\n",
    "#                 top = img.height * coords[0][1]\n",
    "#                 right = img.width * coords[1][0]\n",
    "#                 bottom = img.height * coords[1][1]\n",
    "                \n",
    "#                 # Crop the image to the word\n",
    "#                 word_img = img.crop((left, top, right, bottom))\n",
    "                \n",
    "#                 # Generating a timestamp with the current hour, minute, second, milliseconds as a string\n",
    "#                 # Get the current time\n",
    "#                 current_time_precise = datetime.now()\n",
    "                \n",
    "#                 # Format the time to include hour, minute, second, milliseconds, and day\n",
    "#                 timestamp_precise = current_time_precise.strftime(\"%H%M%S%f\")\n",
    "                \n",
    "#                 # Define the filename with suffix\n",
    "#                 filename = f\"img_{name_of_label}_{timestamp_precise}.png\"\n",
    "                \n",
    "#                 # Save the cropped image with the new filename\n",
    "#                 word_img.save(f\"{annotations_dir}/{filename}\")\n",
    "                \n",
    "#                 # Add the entry to the labels dictionary\n",
    "#                 labels[filename] = name_of_label\n",
    "                \n",
    "# # Save the updated labels dictionary back to the JSON file\n",
    "# with open(labels_file, 'w') as f:\n",
    "#     json.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9908d16-e6db-48c6-81bc-5c9d761b6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual labor: filter out \"dirty annotations\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb7bca-ce10-40a8-8edf-7c355a2c0f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62f4579d-1505-4772-9c67-65da6aa31e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels from the labels.json file\n",
    "with open(labels_file, 'r') as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "# Get a list of all filenames in the 'annotations' directory\n",
    "existing_files = os.listdir(annotations_dir)\n",
    "\n",
    "# Remove keys from the dictionary for files that don't exist\n",
    "labels = {filename: word for filename, word in labels.items() if filename in existing_files}\n",
    "\n",
    "# Save the updated labels dictionary back to the JSON file\n",
    "with open(labels_file, 'w') as f:\n",
    "    json.dump(labels, f)\n",
    "# The labels dictionary is now updated with only existing files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a68a39f-bc21-4b20-becb-8995c1ecd522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation folders if they don't exist\n",
    "train_folder = os.path.join(data_dir, 'train_path')\n",
    "val_folder = os.path.join(data_dir, 'val_path')\n",
    "train_folder_images = os.path.join(train_folder, 'images')\n",
    "val_folder_images = os.path.join(val_folder, 'images')\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(val_folder, exist_ok=True)\n",
    "os.makedirs(train_folder_images, exist_ok=True)\n",
    "os.makedirs(val_folder_images, exist_ok=True)\n",
    "\n",
    "# List all the image files in the folder\n",
    "image_files = os.listdir(annotations_dir)\n",
    "image_files = [i for i in image_files if i!=\"labels.json\"]\n",
    "\n",
    "# Create dictionaries to keep track of counts for each category\n",
    "train_counts = {}\n",
    "val_counts = {}\n",
    "\n",
    "# Define the desired train-validation split ratio\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Iterate through the image files\n",
    "for image_file in image_files:\n",
    "    # Extract the name portion of the filename (e.g., \"img_peter\")\n",
    "    name = image_file.split('_')[0]\n",
    "\n",
    "    # Determine if the image should go to the train or validation set\n",
    "    if name not in train_counts:\n",
    "        train_counts[name] = 0\n",
    "        val_counts[name] = 0\n",
    "\n",
    "    if train_counts[name] / (train_counts[name] + val_counts[name] + 1) < split_ratio:\n",
    "        train_counts[name] += 1\n",
    "        destination_folder = train_folder_images\n",
    "    else:\n",
    "        val_counts[name] += 1\n",
    "        destination_folder = val_folder_images\n",
    "\n",
    "    # Create a copy of the image file in the appropriate folder\n",
    "    source_path = os.path.join(annotations_dir, image_file)\n",
    "    destination_path = os.path.join(destination_folder, image_file)\n",
    "    shutil.copy2(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb691f7f-34af-492a-aa81-0ecd58db8893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [(train_folder, train_folder_images), (val_folder, val_folder_images)]:\n",
    "#     # Load the labels from the labels.json file\n",
    "#     with open(labels_file, 'r') as f:\n",
    "#         labels = json.load(f)\n",
    "    \n",
    "#     # Get a list of all filenames in the 'annotations' directory\n",
    "#     existing_files = os.listdir(i[1])\n",
    "    \n",
    "#     # Remove keys from the dictionary for files that don't exist\n",
    "#     labels = {filename: word for filename, word in labels.items() if filename in existing_files}\n",
    "    \n",
    "#     labels_file_new = os.path.join(i[0], 'labels.json')\n",
    "    \n",
    "#     # Save the updated labels dictionary back to the JSON file\n",
    "#     with open(labels_file_new, 'w') as f:\n",
    "#         json.dump(labels, f)\n",
    "#     # The labels dictionary is now updated with only existing files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4543e7-ea01-4030-bcf8-2e1baf1bdfae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a2236-a882-4da6-8cd4-2c69da68533c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17f047-302a-4496-8cfc-fc214d5c5488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd88da74-3cb3-4a78-8364-f5f7302b68c1",
   "metadata": {},
   "source": [
    "## Labels from user entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "466145f4-d052-4edc-9df2-33b43dd51643",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_entry_annotations_dir = f'{data_dir}/user_entries/annotations'\n",
    "labels_file_user = os.path.join(user_entry_annotations_dir, 'labels.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c7dcfa2-a469-4282-be73-d46466dffd86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all the image files in the folder\n",
    "image_files = os.listdir(user_entry_annotations_dir)\n",
    "image_files = [i for i in image_files if i!=\"labels.json\"]\n",
    "\n",
    "# Create dictionaries to keep track of counts for each category\n",
    "train_counts = {}\n",
    "val_counts = {}\n",
    "\n",
    "# Define the desired train-validation split ratio\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Iterate through the image files\n",
    "for image_file in image_files:\n",
    "    # Extract the name portion of the filename (e.g., \"img_peter\")\n",
    "    name = image_file.split('_')[1]\n",
    "\n",
    "    # Determine if the image should go to the train or validation set\n",
    "    if name not in train_counts:\n",
    "        train_counts[name] = 0\n",
    "        val_counts[name] = 0\n",
    "\n",
    "    if train_counts[name] / (train_counts[name] + val_counts[name] + 1) < split_ratio:\n",
    "        train_counts[name] += 1\n",
    "        destination_folder = train_folder_images\n",
    "    else:\n",
    "        val_counts[name] += 1\n",
    "        destination_folder = val_folder_images\n",
    "\n",
    "    # Create a copy of the image file in the appropriate folder\n",
    "    source_path = os.path.join(user_entry_annotations_dir, image_file)\n",
    "    destination_path = os.path.join(destination_folder, image_file)\n",
    "    shutil.copy2(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5be1aee-e881-4242-92e8-cd47eaeab21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to JSON files\n",
    "first_json_path = f'{user_entry_annotations_dir}/labels.json'\n",
    "second_json_path = f'{annotations_dir}/labels.json'\n",
    "combined_json_path_train = f'{train_folder}/labels.json'\n",
    "combined_json_path_val = f'{val_folder}/labels.json'\n",
    "\n",
    "# Read the content of the first JSON file\n",
    "with open(first_json_path, 'r') as file:\n",
    "    first_data = json.load(file)\n",
    "\n",
    "# Read the content of the second JSON file\n",
    "with open(second_json_path, 'r') as file:\n",
    "    second_data = json.load(file)\n",
    "\n",
    "# Combine the data\n",
    "combined_data = {**first_data, **second_data}\n",
    "\n",
    "# Write the combined data to a new JSON file\n",
    "with open(combined_json_path_train, 'w') as file:\n",
    "    json.dump(combined_data, file, indent=4)\n",
    "with open(combined_json_path_val, 'w') as file:\n",
    "    json.dump(combined_data, file, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d7fffbb-dce7-4ec2-a90f-4be97c050bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [(train_folder, train_folder_images), (val_folder, val_folder_images)]:\n",
    "    # Load the labels from the labels.json file\n",
    "    labels_file_new = os.path.join(i[0], 'labels.json')\n",
    "    with open(labels_file_new, 'r') as f:\n",
    "        labels = json.load(f)\n",
    "    \n",
    "    # Get a list of all filenames in the 'annotations' directory\n",
    "    existing_files = os.listdir(i[1])\n",
    "    \n",
    "    # Remove keys from the dictionary for files that don't exist\n",
    "    labels = {filename: word for filename, word in labels.items() if filename in existing_files}\n",
    "    \n",
    "    labels_file_new = os.path.join(i[0], 'labels.json')\n",
    "    \n",
    "    # Save the updated labels dictionary back to the JSON file\n",
    "    with open(labels_file_new, 'w') as f:\n",
    "        json.dump(labels, f)\n",
    "    # The labels dictionary is now updated with only existing files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b101c13-6d3e-4cb0-bc8c-154dc737da27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
